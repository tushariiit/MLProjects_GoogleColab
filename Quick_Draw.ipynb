{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Quick_Draw.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H3ATAdp_URp"
      },
      "source": [
        "\n",
        "#Quick Draw - A Google Doodle Recognition Clone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlx6-LFL_jbi"
      },
      "source": [
        "This file contains a subset of the quick draw classes. We choose around 100 classes from the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXv-xzU1sd88",
        "outputId": "32556853-754a-4d0c-a4bc-f1d8a2f6bd87"
      },
      "source": [
        "#pip install wget\n",
        "!wget \"https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-28 08:22:02--  https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 760 [text/plain]\n",
            "Saving to: ‘mini_classes.txt’\n",
            "\n",
            "mini_classes.txt    100%[===================>]     760  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-28 08:22:02 (34.2 MB/s) - ‘mini_classes.txt’ saved [760/760]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GL_TdMffD6-"
      },
      "source": [
        "Read the classes names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP-OxOx5sy0b"
      },
      "source": [
        "f = open(\"mini_classes.txt\",\"r\")\n",
        "# And for reading use\n",
        "classes = f.readlines()\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTE6D3uxtMc5"
      },
      "source": [
        "classes = [c.replace('\\n','').replace(' ','_') for c in classes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NDfBHVjACAt"
      },
      "source": [
        "# Download the Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MC_PUS-fKjH"
      },
      "source": [
        "Loop over the classes and download the correspondent data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdSUnpL0u22Q"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22DPhL5FtWcQ"
      },
      "source": [
        "import urllib.request\n",
        "def download():\n",
        "    base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "    for c in classes:        \n",
        "        cls_url = c.replace('_', '%20')\n",
        "        path = base+cls_url+'.npy'\n",
        "        print(path)\n",
        "        urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5jF6TXXu-Bu",
        "outputId": "cc594d54-d6a6-45ca-8573-1a0a4eaec5ea"
      },
      "source": [
        "download()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drums.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/laptop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/anvil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball%20bat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dumbbell.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/traffic%20light.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wristwatch.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shovel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bread.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/table.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tennis%20racquet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/headphones.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lollipop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/power%20outlet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sword.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stop%20sign.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bed.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shorts.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diving%20board.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cell%20phone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/radio.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/axe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tent.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/line.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basketball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pillow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tooth.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/alarm%20clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paper%20clip.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microphone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/envelope.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saw.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frying%20pan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helmet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bridge.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/light%20bulb.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ceiling%20fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/key.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/donut.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beard.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/coffee%20cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bench.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rifle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moustache.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/suitcase.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rainbow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cookie.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lightning.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEdnbBVXAI-X"
      },
      "source": [
        "# Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2FYrPgOKh6t",
        "outputId": "f2280011-3144-4a77-a18b-508c84b6f8aa"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "\n",
        "print(len(os.listdir('data')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o30ipBPAQ5Y"
      },
      "source": [
        "# Load the Data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBq3GXEKAYuO"
      },
      "source": [
        "Each class contains different number samples of arrays stored as .npy format. Since we have some memory limitations we only load 5000 images per class.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HEIgQNHYQnl"
      },
      "source": [
        "def load_data(root, vfold_ratio=0.2, max_items_per_class= 4000 ):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in enumerate(all_files):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    #randomize the dataset \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing \n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6uUjN-WL2Y9"
      },
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhGEDS0SMgLK",
        "outputId": "6702c141-2953-446e-d9ef-3c9e7979d89d"
      },
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNZmQvBWBBHE"
      },
      "source": [
        "Show some random data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "KfpDaHRkyMQC",
        "outputId": "a1398fc2-9b8f-498d-a879-7852541ebbb1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_train))\n",
        "plt.imshow(x_train[idx].reshape(28,28)) \n",
        "print(class_names[int(y_train[idx].item())])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pencil\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8InHz5NBFrV"
      },
      "source": [
        "# Preprocess the Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2GHUq7D2r9e"
      },
      "source": [
        "# Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL6XAb4hBMSc"
      },
      "source": [
        "# The Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YRSRkOyBP1P"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYUVV2wf2z8H",
        "outputId": "cfc70829-b034-4ab8-e5a6-43fe56e55f20"
      },
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(100, activation='softmax')) \n",
        "\n",
        "# Train model\n",
        "adam = tf.optimizers.Adam()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1125/1125 - 28s - loss: 1.9262 - top_k_categorical_accuracy: 0.7793 - val_loss: 1.4033 - val_top_k_categorical_accuracy: 0.8718 - 28s/epoch - 25ms/step\n",
            "Epoch 2/5\n",
            "1125/1125 - 13s - loss: 1.2483 - top_k_categorical_accuracy: 0.8917 - val_loss: 1.1661 - val_top_k_categorical_accuracy: 0.9027 - 13s/epoch - 12ms/step\n",
            "Epoch 3/5\n",
            "1125/1125 - 13s - loss: 1.0852 - top_k_categorical_accuracy: 0.9104 - val_loss: 1.0398 - val_top_k_categorical_accuracy: 0.9138 - 13s/epoch - 12ms/step\n",
            "Epoch 4/5\n",
            "1125/1125 - 15s - loss: 0.9930 - top_k_categorical_accuracy: 0.9198 - val_loss: 0.9811 - val_top_k_categorical_accuracy: 0.9203 - 15s/epoch - 14ms/step\n",
            "Epoch 5/5\n",
            "1125/1125 - 13s - loss: 0.9314 - top_k_categorical_accuracy: 0.9256 - val_loss: 0.9633 - val_top_k_categorical_accuracy: 0.9219 - 13s/epoch - 11ms/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " module_wrapper (ModuleWrapp  (256, 28, 28, 16)        160       \n",
            " er)                                                             \n",
            "                                                                 \n",
            " module_wrapper_1 (ModuleWra  (256, 14, 14, 16)        0         \n",
            " pper)                                                           \n",
            "                                                                 \n",
            " module_wrapper_2 (ModuleWra  (256, 14, 14, 32)        4640      \n",
            " pper)                                                           \n",
            "                                                                 \n",
            " module_wrapper_3 (ModuleWra  (256, 7, 7, 32)          0         \n",
            " pper)                                                           \n",
            "                                                                 \n",
            " module_wrapper_4 (ModuleWra  (256, 7, 7, 64)          18496     \n",
            " pper)                                                           \n",
            "                                                                 \n",
            " module_wrapper_5 (ModuleWra  (256, 3, 3, 64)          0         \n",
            " pper)                                                           \n",
            "                                                                 \n",
            " module_wrapper_6 (ModuleWra  (256, 576)               0         \n",
            " pper)                                                           \n",
            "                                                                 \n",
            " module_wrapper_7 (ModuleWra  (256, 128)               73856     \n",
            " pper)                                                           \n",
            "                                                                 \n",
            " module_wrapper_8 (ModuleWra  (256, 100)               12900     \n",
            " pper)                                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 110,052\n",
            "Trainable params: 110,052\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2KztY7qEn9_"
      },
      "source": [
        "# Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssaZczS7DxeA",
        "outputId": "074beff6-8c91-46c6-e24b-c1974ba8be2e"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuarcy: 93.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xBM_w0VBbNr"
      },
      "source": [
        "# Inference "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "nH3JfoiYHdpk",
        "outputId": "50f70fb0-05c0-4ea2-88e3-cf8f99c9d009"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_test))\n",
        "img = x_test[idx]\n",
        "plt.imshow(img.squeeze()) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8c3db9cb90>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrYTmFByqcN_",
        "outputId": "41c24769-8f11-4880-9852-6a4ea60005cc"
      },
      "source": [
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "ind = (-pred).argsort()[:5]\n",
        "latex = [class_names[x] for x in ind]\n",
        "print(latex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['screwdriver', 'traffic_light', 'knife', 'spoon', 'microphone']\n"
          ]
        }
      ]
    }
  ]
}